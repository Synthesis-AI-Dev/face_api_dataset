{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Coordinate systems and transforms of Synthesis AI face dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "At first, we install some dependencies.\n",
    "\n",
    "Installing `face_api_dataset` from the github it it's not already installed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face_api_dataset is already installed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "(python -c \"import face_api_dataset\")\n",
    "if [ $? -eq 0 ]\n",
    "then\n",
    "    echo \"face_api_dataset is already installed\"\n",
    "else\n",
    "    echo \"installing face_api_dataset from github\"\n",
    "    pip install git+https://github.com/Synthesis-AI-Dev/face_api_dataset.git\n",
    "fi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Installing `git lfs` from the github it it's not already installed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git lfs is already installed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "(git lfs install > /dev/null)\n",
    "if [ $? -eq 0 ]\n",
    "then\n",
    "    echo \"git lfs is already installed\"\n",
    "else\n",
    "    echo \"installing git lfs\"\n",
    "    case \"$(uname -s)\" in\n",
    "\n",
    "       Darwin)\n",
    "         brew install git-lfs\n",
    "         ;;\n",
    "\n",
    "       Linux)\n",
    "         curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
    "         apt-get install git-lfs\n",
    "         ;;\n",
    "\n",
    "       *)\n",
    "         echo \"This cell can't install git lfs your OS. Please take care of it yourself.\"\n",
    "         ;;\n",
    "    esac\n",
    "fi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pulling the test dataset for the example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_dataset is already present\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "if [ -d \"../test_dataset\" ]\n",
    "then\n",
    "    echo \"test_dataset is already present\"\n",
    "else\n",
    "    echo \"downloading test_dataset\"\n",
    "    git clone https://github.com/Synthesis-AI-Dev/face_api_dataset\n",
    "    mv face_api_dataset/test_dataset ..\n",
    "    rm -rf face_api_dataset\n",
    "fi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally we add some imports for the visualisation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import cv2\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use `FaceApiDataset` class to access synthesis datasets.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from face_api_dataset import FaceApiDataset, Modality"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Warning!** Some of modalities requires additional libraries to be installed:\n",
    "`SEGMENTS` and `RGB` modalities use `opencv-python` library,\n",
    " while `DEPTH`, `ALPHA` and `NORMALS` modalities\n",
    " use `tiffile`  and `imagecodecs` libraries for effective work with floating point tiff files.\n",
    " If dataset with these modalities will be created without corresponding libraries present, an `ImportError` is raised.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data_root = \"../test_dataset\"\n",
    "dataset = FaceApiDataset(data_root,\n",
    "                        modalities=[Modality.RGB, Modality.CAM_INTRINSICS, Modality.LANDMARKS_3D_IBUG68,\n",
    "                                    Modality.LANDMARKS_IBUG68\n",
    "                                   ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "13"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are 13 items in the test dataset. Let's explore them closer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "item = dataset[0]\n",
    "item2 = dataset[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each item is a dict with different modalities as keys."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([<Modality.RGB: 2>, <Modality.LANDMARKS_IBUG68: 7>, <Modality.LANDMARKS_3D_IBUG68: 13>, <Modality.CAM_INTRINSICS: 33>])\n"
     ]
    }
   ],
   "source": [
    "print(item.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook we explore camera intrinsics and transistion between 3D and the screen coordinate systems."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.55151515e+03, 0.00000000e+00, 2.56000000e+02],\n       [0.00000000e+00, 1.55151515e+03, 2.56000000e+02],\n       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intrinsics = item[Modality.CAM_INTRINSICS]\n",
    "intrinsics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The camera intrinsics are in OpenCV format:\n",
    "$$\\left [ \\begin{matrix} f_x & 0 & c_x \\\\ 0 & f_y & c_y \\\\ 0 & 0 & 1 \\end{matrix} \\right ]$$,\n",
    "where $f_x$ and $f_y$ are focal distances and $c_x$ and $c_y$ is an optical center\n",
    "(2D coordinates of the point, camera is pointing at on the image).\n",
    "\n",
    "Note, that units of distance in 3D are meters and units in 2D are pixels, the conversion coefficient is already included in $f_x$.\n",
    "\n",
    "$c_x$ and $c_y$ are usually equal to the half of the image resolution as camera is normally pointing to the center of the image."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([256., 256.])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(item[Modality.RGB].shape[:2]) / 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can convert between camera and screen coordinate systems. Let's see how it is done, using ibug68 landmarks."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(-0.07423346489667892, 0.0001043081283569336, -1.0857646465301514)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmark_0 = item[Modality.LANDMARKS_3D_IBUG68]['0']\n",
    "landmark_0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "At first, we need to check that landmark is in front of the camera (z coordinate is negative):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmark_0[2] < 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can convert to screen coordinate system, using intrinsic matrix. However, our 3D camera coordinate system uses OpenGL axis (x right, y top, z towards the camera), and OpenCV system uses a different [one](https://docs.opencv.org/4.5.3/d9/d0c/group__calib3d.html) (x right, y bottom, z from the camera).\n",
    "Thus before we apply the conversion, we need to convert between this coordinate systems, otherwise screen coordinates will be mirrored vertically."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def opengl_to_opencv(x):\n",
    "    return np.array(x) * [1, -1, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To compute landmark in screen coordinates we need to multiply 3D coordinates by the intrinsic matrix."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def cam_to_hom_screen(intrinsics, x):\n",
    "    return intrinsics @ opengl_to_opencv(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "array([162.78140398, 277.79391387,   1.08576465])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_to_hom_screen(intrinsics, landmark_0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We get the result, but it is in homogeneous coordinates. We need to convert it to euclidian."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def from_homogeneous(x):\n",
    "    x = np.array(x)\n",
    "    return x[:2] / x[2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def cam_to_screen(intrinsics, x):\n",
    "    return from_homogeneous(cam_to_hom_screen(intrinsics, x))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "array([149.92328632, 255.85094777])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_to_screen(intrinsics, landmark_0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To check ourselves, let's compare with 2D location of this landmark we get from the info.json:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "(149.9136, 255.8464)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[Modality.LANDMARKS_IBUG68]['0']\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}