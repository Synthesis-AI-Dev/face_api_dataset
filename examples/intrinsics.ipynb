{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Camera intrinsics, screen coordinates and 3D data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we install some dependencies.\n",
    "\n",
    "Installing `face_api_dataset` from the github it it's not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "(python -c \"import face_api_dataset\")\n",
    "if [ $? -eq 0 ]\n",
    "then\n",
    "    echo \"face_api_dataset is already installed\"\n",
    "else\n",
    "    echo \"installing face_api_dataset from github\"\n",
    "    pip install git+https://github.com/Synthesis-AI-Dev/face_api_dataset.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing `git lfs` from the github it it's not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "(git lfs install > /dev/null)\n",
    "if [ $? -eq 0 ]\n",
    "then\n",
    "    echo \"git lfs is already installed\"\n",
    "else\n",
    "    echo \"installing git lfs\"\n",
    "    case \"$(uname -s)\" in\n",
    "\n",
    "       Darwin)\n",
    "         brew install git-lfs\n",
    "         ;;\n",
    "\n",
    "       Linux)\n",
    "         curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
    "         apt-get install git-lfs\n",
    "         ;;\n",
    "\n",
    "       *)\n",
    "         echo \"This cell can't install git lfs your OS. Please take care of it yourself.\"\n",
    "         ;;\n",
    "    esac\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling the test dataset for the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ -d \"../test_dataset\" ]\n",
    "then\n",
    "    echo \"test_dataset is already present\"\n",
    "else\n",
    "    echo \"downloading test_dataset\"\n",
    "    git clone https://github.com/Synthesis-AI-Dev/face_api_dataset\n",
    "    mv face_api_dataset/test_dataset ..\n",
    "    rm -rf face_api_dataset\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we add some imports for the visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `FaceApiDataset` class to access synthesis datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from face_api_dataset import FaceApiDataset, Modality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning!** Some of modalities requires additional libraries to be installed:\n",
    "`SEGMENTS` and `RGB` modalities use `opencv-python` library,\n",
    " while `DEPTH`, `ALPHA` and `NORMALS` modalities\n",
    " use `tiffile`  and `imagecodecs` libraries for effective work with floating point tiff files.\n",
    " If dataset with these modalities will be created without corresponding libraries present, an `ImportError` is raised.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_root = \"../test_dataset\"\n",
    "dataset = FaceApiDataset(data_root,\n",
    "                        modalities=[Modality.RGB, Modality.CAM_INTRINSICS, Modality.LANDMARKS_3D_IBUG68,\n",
    "                                    Modality.LANDMARKS_IBUG68, Modality.DEPTH\n",
    "                                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 13 items in the test dataset. Let's explore them closer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item = dataset[0]\n",
    "item2 = dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item is a dict with different modalities as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(item.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook we explore camera intrinsics and transistion between 3D and the screen coordinate systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "intrinsics = item[Modality.CAM_INTRINSICS]\n",
    "intrinsics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The camera intrinsics are in OpenCV format:\n",
    "$$\\left [ \\begin{matrix} f_x & 0 & c_x \\\\ 0 & f_y & c_y \\\\ 0 & 0 & 1 \\end{matrix} \\right ]$$,\n",
    "where $f_x$ and $f_y$ are focal distances and $c_x$ and $c_y$ is an optical center\n",
    "(2D coordinates of the point, camera is pointing at on the image).\n",
    "\n",
    "Note, that units of distance in 3D are meters and units in 2D are pixels, the conversion coefficient is already included in $f_x$.\n",
    "\n",
    "$c_x$ and $c_y$ are usually equal to the half of the image resolution as camera is normally pointing to the center of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.array(item[Modality.RGB].shape[:2]) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can convert between camera and screen coordinate systems. Let's see how it is done, using ibug68 landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "landmark_0 = item[Modality.LANDMARKS_3D_IBUG68][0]\n",
    "landmark_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At first, we need to check that landmark is in front of the camera (z coordinate is negative):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "landmark_0[2] < 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can convert to screen coordinate system, using intrinsic matrix. However, our 3D camera coordinate system uses OpenGL axis (x right, y top, z towards the camera), and OpenCV system uses a different [one](https://docs.opencv.org/4.5.3/d9/d0c/group__calib3d.html) (x right, y bottom, z from the camera).\n",
    "Thus before we apply the conversion, we need to convert between this coordinate systems, otherwise screen coordinates will be mirrored vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def opengl_to_opencv(x):\n",
    "    return np.array(x) * [1, -1, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To compute landmark in screen coordinates we need to multiply 3D coordinates by the intrinsic matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cam_to_hom_screen(intrinsics, x):\n",
    "    return np.tensordot(opengl_to_opencv(x), intrinsics, axes=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cam_to_hom_screen(intrinsics, landmark_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We get the result, but it is in homogeneous coordinates. We need to convert it to euclidian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def from_homogeneous_2D(xs):\n",
    "    xs_array = np.array(xs)\n",
    "    assert (xs_array.shape[-1] == 3)\n",
    "\n",
    "    slice_but_last = [slice(None)] * (xs_array.ndim - 1) + [slice(None, -1)]\n",
    "    slice_but_last = tuple(slice_but_last)\n",
    "\n",
    "    slice_last = [slice(None)] * (xs_array.ndim - 1) + [slice(-1, None)]\n",
    "    slice_last = tuple(slice_last)\n",
    "    return xs_array[slice_but_last] / xs_array[slice_last]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cam_to_screen(intrinsics, x):\n",
    "    return from_homogeneous_2D(cam_to_hom_screen(intrinsics, x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cam_to_screen(intrinsics, landmark_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To check ourselves, let's compare with 2D location of this landmark we get from the info.json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item[Modality.LANDMARKS_IBUG68]['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's have a look, how landmarks look in 3D.\n",
    "\n",
    "We use ploply to visualise 3D data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x, y, z =  np.array(list(item[Modality.LANDMARKS_3D_IBUG68].values()), dtype=np.float64).transpose()\n",
    "lid = list(item[Modality.LANDMARKS_3D_IBUG68].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's visualize landmarks with labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z, text=lid, mode='markers+text', marker={\"size\": 2})])\n",
    "fig.update_layout(scene_camera={\"eye\": {\"x\": 0., \"y\": 0., \"z\": 2},\n",
    "                                \"up\": {\"x\": 0, \"y\": 1, \"z\": 0}}, title=\"iBUG68 3D labeled\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And without them for more clarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z, mode='markers+text', marker={\"size\": 2})])\n",
    "fig.update_layout(scene_camera={\"eye\": {\"x\": 0., \"y\": 0., \"z\": 2},\n",
    "                                \"up\": {\"x\": 0, \"y\": 1, \"z\": 0}}, title=\"iBUG68 3D\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can project all the landmarks to the screen and check that position is correct on the image as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def landmark_show(img, landmarks, radius=2, labels=True):\n",
    "    l_img = np.copy(img)\n",
    "    for x, y in landmarks:\n",
    "        int_p = (int(x), int(y))\n",
    "        cv2.circle(l_img, int_p, radius=radius, color=(255, 0, 0), thickness=cv2.FILLED)\n",
    "    plt.imshow(l_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "landmarks_2D = cam_to_screen(intrinsics, np.array(list(item[Modality.LANDMARKS_3D_IBUG68].values()), dtype=np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "landmark_show(item[Modality.RGB], landmarks_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From intrinsic transform we can compute reverse intrinsic transform, which is needed to map points from the image to 3D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rev_intrinsics = np.linalg.inv(intrinsics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Screen coordinates are equivealent to the pixel position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shape = item[Modality.RGB].shape\n",
    "screen_xs, screen_ys = np.meshgrid(np.linspace(0, shape[1] - 1, shape[1]),\n",
    "                                   np.linspace(0, shape[0] - 1, shape[0]))\n",
    "depth = item[Modality.DEPTH]\n",
    "color = item[Modality.RGB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To apply reverse projection we need to homogenize the coordinates and multiply them by reversed intrinsic matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xs, ys, zs = np.moveaxis(np.tensordot(np.stack([screen_xs * depth, screen_ys * depth, depth]), rev_intrinsics, axes=(0, 1)), -1, 0) * np.array([1,-1,-1]).reshape(-1, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can show point cloud of the head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(x=xs[zs<0], y=ys[zs<0], z=zs[zs<0],\n",
    "                                   mode='markers+text', marker={\"size\": 1, \"color\": color[zs<0]})])\n",
    "fig.update_layout(scene_camera={\"eye\": {\"x\": 0., \"y\": 0., \"z\": 2},\n",
    "                                \"up\": {\"x\": 0, \"y\": 1, \"z\": 0}}, title=\"Head 3D reconstruction\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To check that everything is correct let's display landmarks at the same 3D plot as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x, y, z =  np.array(list(item[Modality.LANDMARKS_3D_IBUG68].values()), dtype=np.float64).transpose()\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(x=xs[zs<0], y=ys[zs<0], z=zs[zs<0],\n",
    "                                   mode='markers+text', marker={\"size\": 1, \"color\": color[zs<0]}),\n",
    "                      go.Scatter3d(x=x, y=y, z=z, mode='markers+text', marker={\"size\": 3})])\n",
    "fig.update_layout(scene_camera={\"eye\": {\"x\": 0., \"y\": 0., \"z\": 2},\n",
    "                                \"up\": {\"x\": 0, \"y\": 1, \"z\": 0}}, title=\"Head 3D reconstruction with landmarks\",\n",
    "                  showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
