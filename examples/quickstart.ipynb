{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Working with Synthesis AI face dataset\n",
    "At first, we add some imports for the visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We use `FaceApiDataset` class to access synthesis datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from face_api_dataset import FaceApiDataset, Modality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning!** Some of modalities requires additional libraries to be installed:\n",
    "`SEGMENTS` and `RGB` modalities use `opencv-python` library,\n",
    " while `DEPTH`, `ALPHA` and `NORMALS` modalities\n",
    " use `tiffile`  and `imagecodecs` libraries for effective work with floating point tiff files.\n",
    " If dataset with these modalities will be created without corresponding libraries present, an `ImportError` is raised.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_root = \"../test_dataset\"\n",
    "dataset = FaceApiDataset(data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The only required parameter is dataset root. By default all the modailities are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There are 16 items in the test dataset. Let's explore them closer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item = dataset[0]\n",
    "item2 = dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Each item is a dict with different modalities as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(item.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`RENDER_ID` is the id of the image (number used in the stem of the file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item[Modality.RENDER_ID]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`RGB` modality is the rendered image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(item[Modality.RGB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`FACE_BBOX` modality is a face bounding box in format `x0, y0, x1, y1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bbox(image, face_bbox):\n",
    "    plt.figure(figsize=(20,20))\n",
    "\n",
    "    image = cv2.rectangle(image.copy(), face_bbox[:2], face_bbox[2:], (255, 0, 0), 2)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbox(item[Modality.RGB], item[Modality.FACE_BBOX])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`SEGMENTS` modality is the segmentation map. We can see mapping of different segments to numbers with `segments`\n",
    "method o the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset.segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Warning!** `render_id.segments.png` file should not be loaded as is for the segmentation as segment mapping differs\n",
    "between different files. Fortunately `FaceApiDataset` class solves this issue for us.\n",
    "\n",
    "Segmentation is an integral numpy array with the same dimensions as the original image.\n",
    "To display it we write a simple helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def discrete_show(data):\n",
    "    cmap = plt.get_cmap('RdBu', np.max(data) - np.min(data) + 1)\n",
    "    plt.imshow(data, cmap=cmap, vmin=np.min(data) - .5,\n",
    "               vmax = np.max(data) + .5, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's look at segmentation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "discrete_show(item[Modality.SEGMENTS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Different datasets define different segments. If we need to comply to some standards, we may define our own\n",
    "segmentation mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "segments = { 'default': 0,\n",
    "             'background': 0,\n",
    "             'beard': 1,\n",
    "             'body': 3,\n",
    "             'brow': 1,\n",
    "             'cheek_left': 1,\n",
    "             'cheek_right': 1,\n",
    "             'chin': 1,\n",
    "             'clothing': 3,\n",
    "             'ear_left': 1,\n",
    "             'ear_right': 1,\n",
    "             'eye_left': 1,\n",
    "             'eye_right': 1,\n",
    "             'eyelashes': 1,\n",
    "             'eyelid': 1,\n",
    "             'eyes': 1,\n",
    "             'forehead': 1,\n",
    "             'glasses': 0,\n",
    "             'hair': 2,\n",
    "             'head': 1,\n",
    "             'headphones': 0,\n",
    "             'headwear': 0,\n",
    "             'jaw': 1,\n",
    "             'jowl': 1,\n",
    "             'lip_lower': 1,\n",
    "             'lip_upper': 1,\n",
    "             'mask': 0,\n",
    "             'mouth': 1,\n",
    "             'mouthbag': 1,\n",
    "             'mustache': 1,\n",
    "             'neck': 3,\n",
    "             'nose': 1,\n",
    "             'nose_outer': 1,\n",
    "             'nostrils': 1,\n",
    "             'shoulders': 3,\n",
    "             'smile_line': 1,\n",
    "             'teeth': 1,\n",
    "             'temples': 1,\n",
    "             'tongue': 1,\n",
    "             'undereye': 1 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can provide this mapping during the creation of the dataset to change the segmentation modality output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "discrete_show(FaceApiDataset(data_root, segments=segments)[0][Modality.SEGMENTS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Normals modality is a 3-channel numpy array with each chanel values from `-1.0` to `1.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(((item[Modality.NORMALS] + 1) / 2 * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alpha channel is a grayscale image, useful ex. for matting.\n",
    "Unlike segmentation, it can represent semi-transparent parts of the face (ex. hair)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow((item[Modality.ALPHA]).astype(np.uint8), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Depth modality is an array of positive floats. Background is set to have depth equal to `0`,\n",
    "and for the rest of the image it represents distance to camera space in centimeters.\n",
    "\n",
    "We write a simple helper function and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def depth_show(img, shift=0.1):\n",
    "    eps = 0.003\n",
    "    d_min = img[img > eps].min()\n",
    "    d_max = img[img > eps].max()\n",
    "    d_img = np.copy(img)\n",
    "    d_img[d_img < eps] = 0\n",
    "    d_img[d_img > eps] = (d_img[d_img > eps] - d_min) / (d_max - d_min) *  (1 - shift) + shift\n",
    "    plt.imshow((d_img * 255).astype(np.uint8), cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "depth_show(item[Modality.DEPTH])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Landmarks are in iBUG format. Each of 68 landmarks is represented by its `x` and `y` coordinates in image space,\n",
    "`y` coordinate going from top to bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def landmark_show(img, landmarks, radius=2, labels=True):\n",
    "    l_img = np.copy(img)\n",
    "    for name, x, y in landmarks:\n",
    "        int_p = (int(x), int(y))\n",
    "        cv2.circle(l_img, int_p, radius=radius, color=(255, 0, 0), thickness=cv2.FILLED)\n",
    "    plt.imshow(l_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "landmark_show(item[Modality.RGB], item[Modality.LANDMARKS_IBUG68])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Warning!** Contour landmarks are slightly different from iBUG.\n",
    "Instead of showing the contour of the face in our dataset they have the fixed position on the face.\n",
    "\n",
    "This looks a bit strange on rotated images, but these landmarks are more useful for multiple tasks,\n",
    "such as facial pose retrival and special effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "landmark_show(item[Modality.RGB], item[Modality.LANDMARKS_CONTOUR_IBUG68])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "iBUG does not provide landmarks for pupiles, but they can be important in multiple tasks.\n",
    "Thus we provide two additional landmarks for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item[Modality.PUPILS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "landmark_show(item[Modality.RGB], item[Modality.PUPILS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Gaze direction can be important in multiple tasks. We provide gaze direction in\n",
    "format `(horizontale_angle, vertical_angle)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item[Modality.GAZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gaze_show(img, pupils, gaze, length = 100):\n",
    "    g_img = np.copy(img)\n",
    "    start = pupils.astype(np.uint32)\n",
    "    end = (pupils + np.sin(gaze * np.pi / 180.) * length).astype(np.uint32)\n",
    "    for eye in [0, 1]:\n",
    "        cv2.arrowedLine(g_img, tuple(start[eye]), tuple(end[eye]),\n",
    "                        color=(255, 0, 0), thickness=2, tipLength=1)\n",
    "    plt.imshow(g_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "gaze_show(item[Modality.RGB], item[Modality.PUPILS], item[Modality.GAZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "gaze_show(item2[Modality.RGB], item2[Modality.PUPILS], item2[Modality.GAZE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In addition there are modalities to represent different kind of metadata:\n",
    "\n",
    "Identity (for face_id tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item[Modality.IDENTITY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Identity metadata, such as age or gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item[Modality.IDENTITY_METADATA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Information about hairstyle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item[Modality.HAIR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Information about facial hair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item2[Modality.FACIAL_HAIR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If corresponding attribute is not present on the image, the modality is `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item[Modality.FACIAL_HAIR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Expression modality shows facial expression and its intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item[Modality.EXPRESSION]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Usually not all the modalities are needed, so we can only load selected modalities in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset2 = FaceApiDataset(data_root, modalities=[Modality.RGB, Modality.SEGMENTS], segments=segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset2[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Usually there are no problems with the amount of synthetic images,\n",
    "however augmentations are still useful as they help to bridge the reality gap.\n",
    "We can provide transformations in dataset constructor to implement augmentations needed.\n",
    "\n",
    "Below we show how to use `albumentations` library with Synthesis AI dataset for the segmentation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "aug = A.Sequential([A.RandomRotate90(p=1), A.GridDistortion(p=1)])\n",
    "\n",
    "def transform(item):\n",
    "    augmented = aug(image=item[Modality.RGB], mask=item[Modality.SEGMENTS])\n",
    "    return {\n",
    "        Modality.RGB: augmented['image'],\n",
    "        Modality.SEGMENTS: augmented['mask']\n",
    "    }\n",
    "\n",
    "dataset3 = FaceApiDataset(data_root, modalities=[Modality.RGB, Modality.SEGMENTS],\n",
    "                          segments=segments, transform=transform)\n",
    "\n",
    "aug_item = dataset3[0]\n",
    "aug_item2 = dataset3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(aug_item[Modality.RGB])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "discrete_show(aug_item[Modality.SEGMENTS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(aug_item2[Modality.RGB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "discrete_show(aug_item2[Modality.SEGMENTS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
