{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Coordinate systems and transforms of Synthesis AI face dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At first, we install some dependencies.\n",
    "\n",
    "Installing `face_api_dataset` from the github it it's not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face_api_dataset is already installed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "(python -c \"import face_api_dataset\")\n",
    "if [ $? -eq 0 ]\n",
    "then\n",
    "    echo \"face_api_dataset is already installed\"\n",
    "else\n",
    "    echo \"installing face_api_dataset from github\"\n",
    "    pip install git+https://github.com/Synthesis-AI-Dev/face_api_dataset.git\n",
    "fi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Installing `git lfs` from the github it it's not already installed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git lfs is already installed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "(git lfs install > /dev/null)\n",
    "if [ $? -eq 0 ]\n",
    "then\n",
    "    echo \"git lfs is already installed\"\n",
    "else\n",
    "    echo \"installing git lfs\"\n",
    "    case \"$(uname -s)\" in\n",
    "\n",
    "       Darwin)\n",
    "         brew install git-lfs\n",
    "         ;;\n",
    "\n",
    "       Linux)\n",
    "         curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
    "         apt-get install git-lfs\n",
    "         ;;\n",
    "\n",
    "       *)\n",
    "         echo \"This cell can't install git lfs your OS. Please take care of it yourself.\"\n",
    "         ;;\n",
    "    esac\n",
    "fi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pulling the test dataset for the example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_dataset is already present\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "if [ -d \"../test_dataset\" ]\n",
    "then\n",
    "    echo \"test_dataset is already present\"\n",
    "else\n",
    "    echo \"downloading test_dataset\"\n",
    "    git clone https://github.com/Synthesis-AI-Dev/face_api_dataset\n",
    "    mv face_api_dataset/test_dataset ..\n",
    "    rm -rf face_api_dataset\n",
    "fi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally we add some imports for the visualisation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use `FaceApiDataset` class to access synthesis datasets.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from face_api_dataset import FaceApiDataset, Modality"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Warning!** Some of modalities requires additional libraries to be installed:\n",
    "`SEGMENTS` and `RGB` modalities use `opencv-python` library,\n",
    " while `DEPTH`, `ALPHA` and `NORMALS` modalities\n",
    " use `tiffile`  and `imagecodecs` libraries for effective work with floating point tiff files.\n",
    " If dataset with these modalities will be created without corresponding libraries present, an `ImportError` is raised.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data_root = \"../test_dataset\"\n",
    "dataset = FaceApiDataset(data_root,\n",
    "                        modalities=[Modality.RGB, Modality.CAM_TO_HEAD, Modality.HEAD_TO_CAM,\n",
    "                                    Modality.WORLD_TO_HEAD, Modality.HEAD_TO_WORLD, Modality.WORLD_TO_CAM,\n",
    "                                    Modality.CAM_TO_WORLD\n",
    "                                   ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "13"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are 13 items in the test dataset. Let's explore them closer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "item = dataset[0]\n",
    "item2 = dataset[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each item is a dict with different modalities as keys."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([<Modality.RGB: 2>, <Modality.HEAD_TO_CAM: 27>, <Modality.CAM_TO_HEAD: 28>, <Modality.HEAD_TO_WORLD: 29>, <Modality.WORLD_TO_HEAD: 30>, <Modality.CAM_TO_WORLD: 31>, <Modality.WORLD_TO_CAM: 32>])\n"
     ]
    }
   ],
   "source": [
    "print(item.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In Synthesis AI face dataset we use 3 different coordinate systems:\n",
    "1.  World coordinate system.\n",
    "2.  Camera coordinate system.\n",
    "3.  Face coordinate system."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We provide transformations between head,camera and world coordinates systems as 4x4 matrices in homogeneous coordinates."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.93239178,  0.02019352,  0.36088381,  0.38612463],\n       [ 0.06352884,  0.97373945, -0.21862133, -0.23481784],\n       [-0.35582242,  0.22676728,  0.90662398,  0.91507426],\n       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[Modality.CAM_TO_HEAD]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(item[Modality.CAM_TO_HEAD] @ item[Modality.HEAD_TO_CAM], np.eye(4), atol=1e-10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.93239212,  0.06352874, -0.3558217 , -0.01929043],\n       [ 0.0201936 ,  0.97373974,  0.22676736,  1.55267489],\n       [ 0.36088476, -0.21862136,  0.9066242 ,  0.04655426],\n       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[Modality.HEAD_TO_WORLD]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(item[Modality.HEAD_TO_WORLD] @ item[Modality.WORLD_TO_HEAD], np.eye(4), atol=1e-10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.00000000e+00, -1.16382334e-18,  1.40946303e-18,\n         2.08167286e-04],\n       [ 1.16382334e-18,  1.00000000e+00,  6.58739521e-17,\n         1.53932965e+00],\n       [-1.40946303e-18, -6.58739521e-17,  1.00000000e+00,\n         1.06686541e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         1.00000000e+00]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[Modality.CAM_TO_WORLD]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(item[Modality.CAM_TO_WORLD] @ item[Modality.WORLD_TO_CAM], np.eye(4), atol=1e-10)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(item[Modality.CAM_TO_WORLD], item[Modality.HEAD_TO_WORLD] @ item[Modality.CAM_TO_HEAD], atol=1e-10)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}